{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "3yfiW-gc9rbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_pixel_size_path = '/content/drive/My Drive/B3_code/ultrasound_dataset/training_set_pixel_size_and_HC.csv'\n",
        "test_pixel_size_path = '/content/drive/My Drive/B3_code/ultrasound_dataset/test_set_pixel_size.csv'\n",
        "\n",
        "train_df = pd.read_csv(train_pixel_size_path)\n",
        "test_df = pd.read_csv(test_pixel_size_path)\n",
        "\n",
        "train_df.head()\n"
      ],
      "metadata": {
        "id": "x4tp8CkdAvrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_dir = '/content/drive/My Drive/B3_code/ultrasound_dataset/training_set'\n",
        "annotations_dir = '/content/drive/My Drive/B3_code/ultrasound_dataset/training_set'\n"
      ],
      "metadata": {
        "id": "jUIRsyUQAw_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image_and_annotation(image_path, annotation_path):\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    image = cv2.resize(image, (224, 224))\n",
        "    image = image / 255.0\n",
        "\n",
        "    annotation = cv2.imread(annotation_path, cv2.IMREAD_GRAYSCALE)\n",
        "    annotation = cv2.resize(annotation, (224, 224))\n",
        "\n",
        "    return image, annotation\n"
      ],
      "metadata": {
        "id": "IIprMNcyA0H7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(df, images_dir, annotations_dir):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        image_path = os.path.join(images_dir, row['filename'])\n",
        "        annotation_path = os.path.join(\n",
        "            annotations_dir,\n",
        "            row['filename'].replace('.png', '_Annotation.png')\n",
        "        )\n",
        "\n",
        "        image, _ = load_image_and_annotation(image_path, annotation_path)\n",
        "        images.append(image)\n",
        "        labels.append(row['head circumference (mm)'])\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "X_train, y_train = prepare_data(train_df, images_dir, annotations_dir)\n",
        "X_train = X_train.reshape(-1, 224, 224, 1)\n"
      ],
      "metadata": {
        "id": "0dM8b31UA1Z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 1)),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "model = build_model()\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "5iSPeZb7A2Ey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odlc1ETAA7uR",
        "outputId": "84cc155a-e481-45d0-b532-9872fb8a6783"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 3s/step - loss: 9864.9033 - mae: 82.1748 - val_loss: 28099.7520 - val_mae: 160.3346\n",
            "Epoch 2/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 3s/step - loss: 1960.4337 - mae: 35.9413 - val_loss: 21252.3574 - val_mae: 137.9269\n",
            "Epoch 3/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3s/step - loss: 1535.7736 - mae: 32.2755 - val_loss: 19881.3145 - val_mae: 133.8416\n",
            "Epoch 4/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 3s/step - loss: 1088.2583 - mae: 26.5608 - val_loss: 16223.2070 - val_mae: 120.2343\n",
            "Epoch 5/10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_test_data(df, images_dir):\n",
        "    images = []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        image_path = os.path.join(images_dir, row['filename'])\n",
        "        image, _ = load_image_and_annotation(image_path, image_path)\n",
        "        images.append(image)\n",
        "\n",
        "    return np.array(images)\n",
        "\n",
        "X_test = prepare_test_data(\n",
        "    test_df,\n",
        "    '/content/drive/My Drive/B3_code/ultrasound_dataset/test_set'\n",
        ")\n",
        "X_test = X_test.reshape(-1, 224, 224, 1)\n"
      ],
      "metadata": {
        "id": "dCstUAavA-mI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "\n",
        "test_df['predicted_head_circumference'] = y_pred\n",
        "test_df.to_csv(\n",
        "    '/content/drive/My Drive/B3_code/ultrasound_dataset/test_predictions.csv',\n",
        "    index=False\n",
        ")\n",
        "\n",
        "test_df[['filename', 'predicted_head_circumference']].head()\n"
      ],
      "metadata": {
        "id": "vgSnnh3yA_Jx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DQnb-NFyBAPV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}